---
title: "ANALYSING COUNT DATA" 
author: 
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    social: menu
    source_code: embed
runtime: shiny
---
Probability mass functions
===

```{r global, include=FALSE}

  rm(list=ls())
  set.seed(6453)
  library(MASS)      # for neg binomial analysis and correlated data generation
  library(ggplot2)
  library(lme4)
  library(shiny)
  library(utf8)      # codes for Greek letters
  library(MethComp)
  library(gridExtra)
  library(tidyverse)
  library(car)       # diagnostics
  library(vcd)       # diagnostics
  library(skewsamp)  # power for neg binom
  lwd.=3             # used when plotting
  
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  # function to format decimals
  # https://stackoverflow.com/questions/3245862/format-numbers-to-significant-figures-nicely-in-r
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  formatz <- function(x){
    
    if (!is.na(x)  ) {
      
      formatC(signif(x,digits=5), digits=5,format="fg", flag="#",big.mark=",")
      
    }
    
  }
  
  formatz0 <- function(x){
    sprintf(x, fmt = '%s')  
  }
  formatz1 <- function(x){
    sprintf(x, fmt = '%#.1f')  
  }
  formatz2 <- function(x){
    sprintf(x, fmt = '%#.2f')  
  }
  formatz00 <- function(x){
    round(x,0) 
  }
  formatz3 <- function(x){
    sprintf(x, fmt = '%#.3f')  
  }
  formatz4 <- function(x){
    sprintf(x, fmt = '%#.4f')  
  }
  
 
  
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# page 5 Cundill and Alexander BMC Medical Research Methodology (2015) 15:28, return total sample size
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

BMC_negbin_power <- function(pow=.9, mu0=71.7, mu1=50, k0=.33, k1=.33, Q0=.5, type1=0.05) {
  
  A<-qnorm(1-type1/2)
  B <-qnorm(pow)
  Q1 <- 1-Q0
  step1 <- (A+B)
  step2 <- 1/Q1 *( 1/mu1+1/k1)
  step3 <- 1/Q0 *( 1/mu0+1/k0)
  step4 <- log(mu0) - log(mu1)
  N <- ((step1* sqrt(step2+step3))/step4)^2
  return(N)
  
}
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# function for nice upper limits to count bar plots, stack exchange
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  
    roundUpNice <- function(x, nice=c(1,1.5, 2,4,5,6,8,10)) { #added 1.5 to help bar plot y scale
    if(length(x) != 1) stop("'x' must be of length 1")
    10^floor(log10(x)) * nice[[which(x <= 10^floor(log10(x)) * nice)[[1]]]]
  }
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Define the Negative Binomial probability density function, with parameters
# mu and alpha. The mean of this NB distribution is mu, and variance is sigma^2=mu+alpha*mu^2
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
   e_dnbinom=function(x,mu,alpha){
     
    k = 1/alpha
    s1 = lgamma(k+x)-lgamma(k)-lgamma(x+1)    # lgamma is log(gamma)
    s2 = x*log(mu/(mu+k))
    s3 = -k*log(1+mu/k)
    prob = exp(s1+s2+s3)
    prob[x<0] = 0
    prob[prob>1] = 1
    prob[prob<0] = 0
    return(prob)
    
  }

# check
# dnbinom(   1, size=2,   mu=3)
# e_dnbinom(1, alpha=1/2,mu=3)

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This function translates the mu and alpha parameters into an alternative
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
  e_rnbinom=function(n,mu,alpha){
    size = 1/alpha          # so now we can just enter alpha this is converted to 1/ alpha
    prob = size/(mu+size)   # so now we can enter mu the mean and that is converted to prob
    return(rnbinom(n,size=size,prob=prob))
  }

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# generate cor data function, see references
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  GenerateMultivariatePoisson<-function(p, samples, R, lambda){
    normal_mu=rep(0, p)
    normal = mvrnorm(samples, normal_mu, R)
    unif=pnorm(normal)
    pois=t(qpois(t(unif), lambda))
    return(pois)
  }
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# another function to generate cor data , see references
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  mvrnorm <- function(n = 1, mu = 0, Sigma) {
    nvars <- nrow(Sigma)
    # nvars x n matrix of Normal(0, 1)
    nmls <- matrix(rnorm(n * nvars), nrow = nvars)
    # scale and correlate Normal(0, 1), "nmls", to Normal(0, Sigma) by matrix mult
    # with lower triangular of cholesky decomp of covariance matrix
    scaled_correlated_nmls <- t(chol(Sigma)) %*% nmls
    # shift to center around mus to get goal: Normal(mu, Sigma)
    samples <- mu + scaled_correlated_nmls
    # transpose so each variable is a column, not
    # a row, to match what MASS::mvrnorm() returns
    t(samples)
  }
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# function to simulate negative binomial RCT.
# rnbinom simulation accounting for trt discontinuation, outputs p value and other objects
# enter one arm n, k, placebo rate, trt effect, drop off trt rates and follow up time
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  
  nb.power <- function(n=220, k=1.3, mu0=1, eff=0.65, drop1=.1, drop2=.1, fup=1) {
    
    # n=220; alpha=1.3; mu0=1; mu1=.65; drop1=.01; drop2=.01; fup=1; k=.8
    
    mu1 <- eff*mu0 # manifest the true trt effect
    
    # just so there is no error if drop out or k=0
    if (drop1==0) {drop1=0.0001}
    if (drop2==0) {drop2=0.0001}
    if (k==0) {k=0.0001} 
  
    dose <- c(rep("placebo",n),rep("trt",n)) # 50:50 split of patients
    
    mu   <- c(rep(mu0,n), rep(mu1,n))        # rates in two arms
  
    drop <- c(rep(drop1,n), rep(drop2,n))    # tr discontinuation rates
    
    f <- - rexp(2*n) / log(1-drop/fup)       # generate drop outs and scale time according to follow up!
    
    indiv.time <- ifelse(f > fup, fup, f)    # curtail at follow up time 
    
    y  <-  rnbinom(n*2,  prob=1/(1+ mu*indiv.time* k),        size=1/k)  +   # on treatment events
           rnbinom(n*2,  prob=1/(1+ mu0*(fup-indiv.time)*k),  size=1/k)      # accounting for any time off treat. 
    
    # assume no one is lost to the study but can discontinue treatment
    logtime  <- rep(log(fup), n*2)          # make sure follow up here !
    
    # analyse with negative binomial model
    mod <- glm.nb(y~dose+offset((logtime)))
    
    x <- summary(mod)
   
    # collect p-values and other stats
    p <-  x$coefficients["dosetrt","Pr(>|z|)"]
     
    return(list(p, y ,dose, x, mod, logtime))
    
  } 

    # example1 <-  nb.power(n=220, k=1.3, mu0=1, eff=.65, drop1=.1, drop2=.1, fup=1)
    # barplot(unlist(table(example1[2])))
    # 
    # res <- replicate( 1000, 
    #      nb.power(n=220, k=1.3, mu0=1, eff=.65, drop1=.1, drop2=.1, fup=1))
    # mean(unlist(res[1,]<.05))
  
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# function to simulate negative binomial RCT
# gamma Poisson simulation accounting for trt discontinuation, outputs p value and other objects
# enter one arm n, k, placebo rate, trt effect, drop off trt rates and follow up time
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  
nb.power2 <- function(n=220, k=1.3, mu0=1, eff=0.65, drop1=.1, drop2=.1, fup=1) {
  
  mu1 <- eff*mu0
  
  # n=220; alpha=1.3; mu0=1; mu1=.65; drop1=.1; drop2=.1; fup=1; k=.8
  # just so there is no error if drop out is or k=0
  
  if (drop1==0) {drop1=0.0001}
  if (drop2==0) {drop2=0.0001}
  if (k==0) {k=0.0001} 
  
  dose <- c(rep("placebo",n),rep("trt",n)) # 50:50 split of patients
  
  mu   <- c(rep(mu0,n), rep(mu1,n))        # rates in two arms
  
  drop <- c(rep(drop1,n), rep(drop2,n))    # tr discontinuation rates
  
  f <- - rexp(2*n) / log(1-drop/fup)       # generate drop outs and scale time according to follow up!
  
  indiv.time <- ifelse(f > fup, fup, f)    # curtail at follow up time 

  s <-  rgamma(2*n, shape = 1/k, scale = k)
  
  # lambda1 <- mu   * s  # Simulate rate
  # y <-   rpois(n = n*2, lambda = (indiv.time*lambda1))  +
  #        rpois(n = n*2, lambda = ((fup-indiv.time)*lambda1))  # ensure follow up here!
  
  y <- rpois(n = n*2, lambda = (indiv.time*mu*s))  +
       rpois(n = n*2, lambda = ((fup-indiv.time)*mu0*s))  # ensure follow up here!
  
  # this parametrisation see MASS::rngebin code
  theta <- 1/k
  y <- rpois(2*n, (indiv.time* mu *        rgamma(2*n, theta))/theta) +
       rpois(2*n, ((fup-indiv.time)* mu0 * rgamma(2*n, theta))/theta)
  
  
  # assume no one is lost to the study but can discontinue treatment
  logtime  <- rep(log(fup), n*2)          # make sure follow up here !
  
  # analyse with neg. binomial model
  mod <- glm.nb(y~dose+offset((logtime)))
  x <- summary(mod)
  
  # collect p-values
  p <-  x$coefficients["dosetrt","Pr(>|z|)"]
  
  return(list(p, y ,dose,x,mod, logtime))
  
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# simpler functions to allow comparison with canned functions
# no follow up nor drop outs 
# start simpler functions
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

nb.power.simp <- function(n=505, k=1/.33, mu0=71.4, eff=0.7,   fup=1) {
  
  mu1 <- eff*mu0
  
  dose <- c(rep("placebo",n),rep("trt",n)) # 50:50 split of patients
  
  mu   <- c(rep(mu0,n), rep(mu1,n))        # rates in two arms
  
  y  <-  rnbinom(n*2,  prob=1/(1+ mu*fup* k),        size=1/k)  
  
  # assume no one is lost to the study but can discontinue treatment
  logleng  <- rep(log(fup), n*2)            # make sure follow up here !
  
  # analyse with neg. binomial model
  x <- summary(MASS::glm.nb(y~dose+offset((logleng))))
  
  # collect p-values
  p <-  x$coefficients["dosetrt","Pr(>|z|)"]
  
  # return(p)
  
  return(list(p, x))
  
}  

nb.power2.simp <- function(n=220, k=1.3, mu0=1, eff=0.65,   fup=1) {
  
  mu1 <- eff*mu0

  dose <- c(rep("placebo",n),rep("trt",n)) # 50:50 split of patients
  
  mu   <- c(rep(mu0,n), rep(mu1,n))        # rates in two arms
   
  s <-  rgamma(n*2, shape = 1/k, scale = k)
   
  lambda1 <- mu   * s  ## Simulate rate

  y <-   rpois(n = n*2, lambda = (fup*lambda1))   
  # assume no one is lost to the study but can discontinue treatment
  logleng  <- rep(log(fup), n*2)            # make sure follow up here !
  
  # analyse with neg. binomial model
  x <- summary(MASS::glm.nb(y~dose+offset((logleng))))
  
  # collect p-values
  p <-  x$coefficients["dosetrt","Pr(>|z|)"]
  
  return(p)
  
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# end simpler functions
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# function to generate correlated poisson and analyse and evaluate
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

po.cor.power <- function(n=22, r=.75, mu0=10, eff.p=.75) { # r correlation mu0 placebo rate, mu1 expected change in rate
   
  #n=22; r=.75; mu0=10; eff.p=.75
  # 1. create correlated poisson
  # 2. analyse many times and examine

  L1 <- mu0
  L2 <- mu0*eff.p
  
  # generate correlated poisson ref: https://thomasward.com/simulating-correlated-data/
  # Sample correlated N(0, 1) distributions from a multivariate normal distribution.
  # Transform them to correlated Uniform(0, 1) distributions with the normal CDF.
  # Transform them to any correlated probability distribution you desire with that probability distribution’s inverse CDF.
  
  Sigma <- matrix(c(1, r, r, 1), 2, 2)
 
  p2 <- mvrnorm(n, Sigma = Sigma)   # correlated continuous, see function in global area!
  
  U <- pnorm(p2, mean = 0, sd = 1)  # correlated uniform
  pp1 <- qpois(U[, 1], L1)          # correlated poisson
  pp2 <- qpois(U[, 2], L2)          # correlated poisson
  
  cor. <- cor(pp1,pp2)              # capture correlation
  
  # create a data frame
  my_data <- data.frame( 
    group = rep(c("A.before", "B.after"), each = n),
    counts = c(pp1,  pp2),
    ID=rep(1:n,2)
  )
  
  # mixed model
  A <- glmer(counts ~ group + (1|ID), data=my_data, family="poisson")
  
  # B <-    glmer(counts ~ 1     + (1|ID), data=my_data, family="poisson")  # dont use LRT to speed up sims
  # p <-    anova(A,B)
  # mix <-  p$`Pr(>Chisq)`[2]
  
  x <- summary(A)
  mix <- summary(A)$coeff[2,"Pr(>|z|)"]  # to speed up simulations we don't use LR test but Wald test
  
  rate.reduction <- exp(x$coefficients[2,1])
  
  intercept <- exp( x$coefficients[1,1])
  beta      <- exp( x$coefficients[2,1])
  
  x1 <- pp2 - pp1                                                                         # post - pre
  
  w <- wilcox.test(x=x1, paired=FALSE, correct=FALSE, conf.int=TRUE  ,conf.level = 0.95)  # paired is false as we have taken the difference in pairs
   
  wil <- w$p.value
  wile <- w$estimate[1][[1]]
  
  t.t <- t.test(x=x1, paired=FALSE)$p.value # t.test(x1)$p.value 
   
  signed_rank = function(x) sign(x) * rank(abs(x))
  ttor <- t.test(signed_rank(x1))$p.value
  
  # wilcox.test(x1)
  # t.test(signed_rank(x1))
  
  #lets capture SD of differences
  sdd <- sd(x1)
  
  #newList <- list("glmer" = mix , "Wilcoxon signed rank test" = wil,
              #    "t.test"=t.t, "rate reduction"= rate.reduction, "intercept"=intercept, "beta"=beta,
               #   "ttest on ranks"=ttor, "sd of diff"=sdd)
  #return(newList)
   # collect all relevant info
   c(rate.reduction,mix , wil,t.t,  ttor,intercept, beta ,sdd, wile, cor.)
  
}

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# start of app
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```

Column {.sidebar}
-----------------------------------------------------------------------

**Count data analysis is explored**

```{r tab1}

 
  sliderInput('mu', 'Common  \u03BC', value=1.5,
                min = 1, max = 25, step=.5, ticks=F)
  
  sliderInput('alpha_a', '\u03B1 for red curve', value = c(1.3),
                min = 0, max = 5 ,step=0.01, ticks=F)
  
  sliderInput('alpha_b', '\u03B1 for dark blue curve', value = c(1.3),
                min = 0, max = 5 ,step=0.01, ticks=F)
  
  sliderInput('alpha_d', '\u03B1 for purple curve', value = c(1.3),
                min = 0, max = 5 ,step=0.01, ticks=F)
  
  sliderInput('sims', 'Simulations (chart 2)', 50000,
                min = 50000, max = 500000,step=50000,ticks=F)
  
  sliderInput('x_range', 'Plot x-range', value = c(0,10),
          min = 0, max = 80,step=5,ticks=F)
  
  sliderInput('y_range', 'Plot y-range', value = c(0,.5),
          min = 0, max = 1,step=.05,ticks=F)

  checkboxInput('perc','show stats on barplot', value=TRUE)

```

$\alpha$ takes on positive rational values, rarely above 4 (ref 11 page 190). Values of $\alpha$ greater than 2 usually indicate that there is substantial over-dispersion.

When $\alpha$ approaches 0, k approaches infinity and Poisson emerges (move red $\alpha$ slider to 0).

When $\alpha$ > 1, k < 1 leads to over dispersed data.

$\alpha$ = 1/k ; k = 1/ $\alpha$ see next tab.
 

Column {data-width=600, height=600}
-----------------------------------------------------------------------
### Chart 1


```{r tab1 plot1}

renderPlot({

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Cannot find the reference that helped with code in this tab!
# NB density function, and overlay the Poisson distribution with the same mean
# Normal with variance equal to mean also
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
  mu =      input$mu
  alpha_a = input$alpha_a
  alpha_b = input$alpha_b
  alpha_d = input$alpha_d
  low =     input$x_range[1]
  high=     input$x_range[2]
  xmax =    high
  ymax =    input$y_range[2]

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  # if else to turn neg binomial into poisson if alpha =0
  x=c(-0.0001,seq(0,xmax,1))
  
  y =          dpois(x,mu)
   
  if(alpha_a==0) {
  yb =          dpois(x,mu)
  }else{
  yb=     e_dnbinom(x,mu,alpha_a)
  }
  
  if(alpha_b==0){
  yc =          dpois(x,mu)
  }else{
  yc=     e_dnbinom(x,mu,alpha_b)
  }
  
  if(alpha_d==0){
  yd =          dpois(x,mu)
  }else{
  yd=     e_dnbinom(x,mu,alpha_d)
  }
  
  nor <- dnorm(x, mu, sqrt(mu))
 
  x=  c(0,x)  
  y=  c(0,y)
  yb= c(0,yb)
  yc= c(0,yc)
  yd= c(0,yd)
  nor=c(0,nor)
  
  l = !is.na(y+yb+yc+yd+nor)
  
  plot(x[l],y[l], ylim=c(0,ymax), xlim=c(low,xmax), type="l", lwd=lwd., xlab="x",
       ylab="prob(x)", main="Probability distributions")
  
  lines(x[l],yb[l], col=2,lwd=lwd.,type="l")
  lines(x[l],yc[l], col=4,lwd=lwd.,type="l")
  lines(x[l],nor[l],col=5,lwd=lwd.,type="l")
  lines(x[l],yd[l], col=6,lwd=lwd.,type="l")
   
  apois = paste("Poisson \u03BC=", mu,sep="")
  nb_a =  paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_a,sep="")
  nb_b =  paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_b,sep="")
  nb_c =  paste("Normal \u03BC=",   mu," \u03C3=sqrt(",mu,")",sep="")
  nb_d =  paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_d,sep="")
  
  legend("topright",col=c(1,2,4,6,5),legend=c(apois, nb_a, nb_b, nb_d, nb_c), lwd=lwd.,bty="n")
 }
)

``` 
### Chart 2

```{r, tab1 plot2}

renderPlot({
  
    n=input$sims
    
    mu = input$mu
    alpha_a =  input$alpha_a
    alpha_b =  input$alpha_b
    alpha_d =  input$alpha_d
    low =      input$x_range[1]
    xmax=      input$x_range[2]
    ymax =     input$y_range[2]
    
    z  =      rpois(n,mu)
    zb = e_rnbinom(n,mu,alpha_a)
    zc = e_rnbinom(n,mu,alpha_b)
    zd =      rnorm(n,mu,sqrt(mu))
    ze = e_rnbinom(n,mu,alpha_d)
    
    a=hist(z, plot=F,breaks=seq(-1.5,n+.5,1))
    b=hist(zb,plot=F,breaks=seq(-1.5,n+.5,1))
    c=hist(zc,plot=F,breaks=seq(-1.5,n+.5,1))
    d=hist(zd,plot=F,breaks=200)
    e=hist(ze,plot=F,breaks=seq(-1.5,n+.5,1))
    
    atitle = paste("Distributions based on",n,"random draws")
    
    plot(a$mids,a$density,type="s",lwd=lwd., col=1, ylim=c(0,ymax),
         main=atitle, xlim=c(low,xmax),
         xlab="x", ylab="Fraction falling within each bin")
    
    lines(b$mids,b$density,type="s",lwd=lwd.,col=2)
    lines(c$mids,c$density,type="s",lwd=lwd.,col=4)
    lines(d$mids,d$density,type="s",lwd=lwd.,col=5)
    lines(e$mids,e$density,type="s",lwd=lwd.,col=6)
    
    apois = paste("Poisson \u03BC="  ,mu,  sep="")
    nb_a =  paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_a,     sep="")
    nb_b =  paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_b,     sep="")
    nb_c =  paste("Normal \u03BC=",   mu," \u03C3=sqrt(",mu,")", sep="")
    nb_d =  paste("Neg Binom \u03BC=",mu," \u03B1=",alpha_d,     sep="")
    
    legend("topright",col=c(1,2,4,6,5),legend=c(apois, nb_a, nb_b, nb_d, nb_c),
           lwd=lwd.,bty="n")

})

```  

References
====
```{r, refs}
 
    tags$a(href = "https://stats.stackexchange.com/questions/71194/fitting-a-poisson-distribution-with-lme4-and-nlme", target="_blank",
           tags$span(style="color:blue", "[1] Poisson with lme4 and nlme"),) 
    div(p(" "))
    tags$a(href = "https://stats.stackexchange.com/questions/27869/fitting-a-poisson-glm-mixed-model-with-a-random-slope-and-intercept",target="_blank",
           tags$span(style="color:blue", "[2] Mixed model Poisson"),)
    div(p(" "))
    tags$a(href = "https://stackoverflow.com/questions/6044800/adding-greek-character-to-axis-title", target="_blank",
           tags$span(style="color:blue", "[3] Adding Greek characters - shiny"),)
    div(p(" "))
    tags$a(href = "https://stackoverflow.com/questions/52225348/shiny-flexdashboard-reference-object-in-new-tabset#52225733", target="_blank",
           tags$span(style="color:blue", "[4] Reference object in new tab - shiny"),)  
    div(p(" "))
    tags$a(href = "https://journals.sagepub.com/doi/pdf/10.1177/1536867X1201200202", target="_blank",
           tags$span(style="color:blue", "[5] What hypotheses do “nonparametric” two-group tests actually test?"),) 
    div(p(" "))
    tags$a(href = "https://www.google.co.uk/books/edition/Discrete_Data_Analysis_with_R/danODwAAQBAJ?hl=en",target="_blank",
           tags$span(style="color:blue", "[6] Discrete Data Analysis with R Visualization and Modeling Techniques for Categorical and Count Data"),) 
    div(p(" "))
    tags$a(href = "https://www.galitshmueli.com/system/files/ASMB_901_rev.pdf",target="_blank",
           tags$span(style="color:blue", "[7] On generating multivariate Poisson data in management science applications"),) 
    div(p(" "))
    tags$a(href = "https://thomasward.com/simulating-correlated-data/",target="_blank",
           tags$span(style="color:blue", "[8] Simulating correlated data"),) 
    div(p(" "))
    tags$a(href = "https://www.rdocumentation.org/packages/simstudy/versions/0.3.0", target="_blank", 
           tags$span(style="color:blue", "[9] package simstudy for simulating correlated data, not used but interesting"),) 
    div(p(" "))
    tags$a(href = "https://www.rdocumentation.org/packages/SimCorrMix/versions/0.1.1/topics/SimCorrMix",target="_blank", 
           tags$span(style="color:blue", "[10] package SimCorrMix for simulating correlated data, not used but interesting"),) 
    div(p(" "))
    tags$a(href = "https://www.amazon.com/Negative-Binomial-Regression-Joseph-Hilbe/dp/0521198151",target="_blank", 
           tags$span(style="color:blue", "[11] Negative Binomial Regression 2nd Edition by Joseph M. Hilbe"),) 
    div(p(" "))
    tags$a(href = "https://www.amazon.co.uk/Discrete-Data-Analysis-Visualization-Categorical/dp/149872583X",target="_blank", 
           tags$span(style="color:blue", "[12] Discrete Data Analysis with R: Visualization and Modeling Techniques for Categorical and Count Data, Michael Friendly, David Meyer"),) 
    div(p(" "))
    tags$a(href = "https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-015-0023-0.pdf",target="_blank",
           tags$span(style="color:blue", "[13] Sample size calculations for skewed distributions - see canned power tab"),) 
    div(p(" "))
      tags$a(href = "https://pubmed.ncbi.nlm.nih.gov/17230434/", target="_blank",
           tags$span(style="color:blue", "[14] Analysis of exacerbation rates in asthma and chronic obstructive pulmonary disease: example from the TRISTAN study - see canned power tab "),) 
    div(p(" "))
    tags$a(href = "https://stats.stackexchange.com/questions/10419/what-is-theta-in-a-negative-binomial-regression-fitted-with-r", target="_blank",
           tags$span(style="color:blue", "[15] J Hilbe explains what is reported by R's negative binomial model output "),) 
    div(p(" "))
     tags$a(href = "https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5947", target="_blank",
           tags$span(style="color:blue", "[16] H. Zhu and H. Lakkis (2014). Sample size calculation for comparing two negative binomial rates, Statistics in Medicine, 33:376-387"),) 
     div(p(" "))
     tags$a(href = "https://www.ejobrien.com/", target="_blank",
           tags$span(style="color:blue", "[17] Sixty percent of the time it works every time <- more apps here!"),) 
    div(p(" "))
  tags$hr()                        

```